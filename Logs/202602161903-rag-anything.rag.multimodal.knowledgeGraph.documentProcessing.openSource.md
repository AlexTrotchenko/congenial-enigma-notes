---
title: Tool Note - RAG-Anything
vendor: HKUDS (HKU Data Science)
date: 202602161903
categories: [rag, multimodal, knowledgeGraph, documentProcessing, python, openSource]
pricing: free
platforms: [windows, mac, linux]
source: https://github.com/HKUDS/RAG-Anything
documentation: https://github.com/HKUDS/RAG-Anything/blob/main/docs/
type: tool
---

# RAG-Anything - All-in-One Multimodal RAG Framework

## Overview

RAG-Anything is a comprehensive multimodal RAG (Retrieval-Augmented Generation) system built on LightRAG that can process and query documents containing text, images, tables, equations, charts, and multimedia. Unlike traditional text-focused RAG systems, it handles all content modalities through a single unified framework, making it ideal for academic papers, technical documentation, financial reports, and enterprise knowledge management.

## Core Features

- **End-to-end multimodal pipeline** — complete workflow from document ingestion to intelligent multimodal query answering
- **Universal document support** — PDFs, Office documents (DOC/DOCX/PPT/PPTX/XLS/XLSX), images, and diverse formats
- **Specialized content analyzers** — dedicated processors for images, tables, mathematical equations
- **Multimodal knowledge graph** — automatic entity extraction and cross-modal relationship discovery
- **VLM-enhanced query mode** — integrates images into vision-language models for deeper multimodal analysis
- **MinerU integration** — high-fidelity document structure extraction and semantic preservation
- **Hybrid intelligent retrieval** — vector similarity + graph traversal for comprehensive search
- **Direct content list insertion** — bypass parsing by inserting pre-parsed content from external sources

## Architecture Pipeline

```
Document Parsing → Content Analysis → Knowledge Graph → Intelligent Retrieval
```

**Stage 1: Document Parsing**
- MinerU for structure extraction
- Adaptive content decomposition (text, visuals, tables, equations)
- Universal format support

**Stage 2: Multimodal Content Processing**
- Autonomous content categorization and routing
- Concurrent multi-pipeline processing
- Document hierarchy preservation

**Stage 3: Specialized Analyzers**
- Visual Content Analyzer (vision models)
- Structured Data Interpreter (tables, statistical patterns)
- Mathematical Expression Parser (LaTeX support)
- Extensible plugin architecture for new modalities

**Stage 4: Knowledge Graph**
- Multi-modal entity extraction
- Cross-modal relationship mapping
- Weighted relevance scoring

**Stage 5: Retrieval**
- Vector-graph fusion search
- Modality-aware ranking
- Relational coherence maintenance

## Quick Start Guide

1. Install from PyPI:
   ```bash
   pip install raganything
   # Or with all extras:
   pip install 'raganything[all]'
   ```

2. Office documents require LibreOffice:
   ```bash
   # macOS
   brew install --cask libreoffice
   # Ubuntu
   sudo apt-get install libreoffice
   ```

3. Basic usage:
   ```python
   from raganything import RAGAnything, RAGAnythingConfig
   
   config = RAGAnythingConfig(
       working_dir="./rag_storage",
       parser="mineru",
       enable_image_processing=True,
       enable_table_processing=True,
       enable_equation_processing=True,
   )
   
   rag = RAGAnything(
       config=config,
       llm_model_func=llm_model_func,
       vision_model_func=vision_model_func,
       embedding_func=embedding_func,
   )
   
   await rag.process_document_complete("document.pdf", "./output")
   result = await rag.aquery("What are the main findings?")
   ```

## Use Cases

- **Academic research** — query papers with figures, equations, and tables
- **Technical documentation** — RAG over manuals with diagrams and code
- **Financial reports** — extract insights from charts, tables, and text
- **Enterprise knowledge management** — unified search across mixed-content documents
- **Legal document analysis** — process contracts with tables and structured data
- **Medical literature** — handle papers with medical imaging and data tables

## Technical Details

- **Pricing Model:** Free and open-source
- **Platform Support:** Python, cross-platform
- **Dependencies:** LightRAG, MinerU (document parsing), OpenAI/compatible LLMs
- **Optional Extras:** `[image]` for BMP/TIFF/GIF/WebP, `[text]` for TXT/MD
- **Parser Options:** MinerU (default) or Docling
- **Parse Methods:** auto, ocr, or txt

## Resources

- [GitHub Repository](https://github.com/HKUDS/RAG-Anything)
- [Technical Report (arXiv)](http://arxiv.org/abs/2510.12323)
- [LightRAG (Base Framework)](https://github.com/HKUDS/LightRAG)
- [MinerU (Document Parser)](https://github.com/opendatalab/MinerU)
- [Context Configuration Docs](https://github.com/HKUDS/RAG-Anything/blob/main/docs/context_aware_processing.md)

## Notes & Considerations

RAG-Anything solves the problem of traditional RAG systems ignoring non-text content (images, tables, equations) by building a multimodal knowledge graph that preserves cross-modal relationships. Built on LightRAG with MinerU for document parsing. The VLM-enhanced query mode (added Aug 2025) automatically integrates relevant images into vision model queries for deeper analysis. Requires an LLM API (OpenAI or compatible) and optionally a vision model for image processing. LibreOffice needed for Office document support. Models are downloaded automatically on first use.
